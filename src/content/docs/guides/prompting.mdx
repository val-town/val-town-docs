---
title: LLM prompting
description: A guide to LLM prompting and using AI inside Val Town
tableOfContents: false
---

import Val from "@components/Val.astro";
import {
  LinkButton,
  Tabs,
  TabItem,
  LinkCard,
  CardGrid,
} from "@astrojs/starlight/components";

Val Town provides multiple ways to code with AI.

### Townie

[Townie](https://townie.val.run) is our coding assistant that helps you code in Val Town from your browser.

### Local development

You can code with AI in your favorite editor, like VS Code, Zed, Cursor, or Windsurf.

1. Install [the Val Town CLI](https://github.com/val-town/vt)
2. Add our [system prompt](https://www.val.town/x/valdottown/Townie/code/prompts/system_prompt.txt) to...
   - [Cursor](https://docs.cursor.com/context/rules-for-ai)
   - [Windsurf](https://docs.windsurf.com/chat/overview#persistent-context)
   - [Zed](https://zed.dev/docs/assistant/commands)
   - [GitHub Copilot](https://docs.github.com/en/copilot/customizing-copilot/adding-repository-custom-instructions-for-github-copilot)

### Troubleshooting

- Broken code? Visit the `Versions` tab or `History` of your val to revert.
- Large changes? Use feature [branches](/vals/branches) and [merge](/vals/pull-requests) when stable.
- Need help? Ask in the [Val Town Discord](https://discord.val.town/) in the `#local-dev` channel
